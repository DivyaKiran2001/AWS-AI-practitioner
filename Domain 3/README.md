# Domain 3: Amazon Bedrock and Generative AI Lifecycle

## ğŸ“˜ Knowledge Bases for Amazon Bedrock

- Fully managed capability to implement the entire RAG workflow
- No need for custom integrations to data sources
- Manages:
  - Data Ingestion
  - Chunking
  - Creation and storage of vector embeddings

### ğŸ”§ Implementation of Knowledge Bases

1. **Data Source**
   - Create an S3 Bucket and upload relevant files
2. **Create Amazon Knowledge Base** in AWS

---

## ğŸ¤– Amazon Bedrock Agents

- Agents orchestrate interactions between:
  - Foundation Models (FMs)
  - Data sources
  - Software applications
  - User conversations

---

## ğŸ—ï¸ Amazon Bedrock Architecture

**CoT (Chain of Thought) Reasoning**

- Pre-processing  
- Orchestration  
- Post-processing

---

## ğŸ›¡ï¸ Amazon Bedrock Guardrails

- Safeguards on top of FMsâ€™ native protection
- Filters harmful content based on Responsible AI policies
- Blocks undesirable topics in GenAI applications

---

## ğŸ›ï¸ Inference Parameters

Inference parameters influence the response generated by the model. They fall into three categories:

### 1. ğŸ² Randomness and Diversity

**Prompt Example:** _"I hear the hoof beats of..."_

- **Temperature**
  - Low (closer to 0): Higher probability words
  - High (closer to 1 or 5): Lower probability words can be selected
- **Top K (1-500)**
  - Limits the selection to top K most probable words
  - Example: If K = 50, model selects from top 50 words
- **Top P (0.01-0.99)**
  - Caps choices based on cumulative probability
  - Example: If Top P = 0.5, â€œHorseâ€ (0.4) and â€œWindâ€ (0.2) may be selected

### 2. ğŸ“ Length

**Prompt Example:** _"Write an essay on horse"_

- **Length**: Controls response size and cost
- **Max Length (1â€“4096 tokens)**: Maximum tokens in response
- **Stop Sequence**: Configure up to 4 sequences to stop generation. The returned text excludes the stop sequence.

### 3. ğŸ” Repetition

Controls repetition in responses:

- **Presence Penalty (0-5)**: Higher values reduce repetition
- **Count Penalty (0-1)**: Penalizes tokens that appear repeatedly
- **Frequency Penalty (0-500)**: Penalizes based on frequency (normalized to text length)
- **Penalize Special Tokens**: Reduces repetition of whitespaces, punctuation, etc.

---

## ğŸ“Š Amazon Bedrock Logging and Monitoring

- Use **Amazon CloudWatch** to monitor all parts of your Amazon Bedrock application

---

# ğŸ”„ Generative AI Lifecycle (04/04/2025)

### 1. âœ… Use Case Selection

### 2. ğŸ§  Foundation Model Selection

- **Modality**: Text | Image | Embedding (e.g., Command, Anthropic)
- **Size**: Model parameters (e.g., 50B)
- **Inference Speed**: Response latency
- **Context Window**: 77Kâ€“200K tokens (Claude has max)
- **Pricing & Deployment**: Varies based on AWS services
- **Training Dataset**: Internet, code, human feedback
- **Proprietary or Open Source**: Prefer open-source
- **Fine-tunable**: Should allow fine-tuning
- **Additional Features**: Multilingual support (e.g., Jurassic, Titan)
- **Quality of Response**: Accuracy, toxicity, robustness

---

## ğŸ“ Foundation Model Evaluation Metrics

### 1. ROUGE

- Evaluates text summarization
- **ROUGE-N**: Matches n-grams
- **ROUGE-L**: Longest common subsequence (LCS)

### 2. BLEU

- **Use Case**: Machine translation tasks

### 3. BERT Score

- Evaluates text generation quality (e.g., summarization)

---

## ğŸ§ª Model Evaluation Service

### 1. Automatic Evaluation

- Tasks: Text Generation, Summarization, Q&A, Classification

### 2. Human Evaluation

- Bring your own work team

### 3. AWS Managed Work Team

---

## ğŸ§­ Adapt and Align Foundation Model

### ğŸ§‘â€ğŸ’» Prompt Engineering Techniques

- **Zero-Shot Prompting**: No examples provided
- **One-Shot Prompting**: One example provided
- **Few-Shot Prompting**: Few examples provided

---
